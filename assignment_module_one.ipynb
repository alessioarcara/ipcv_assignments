{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Product Recognition of Food Products**\n","\n","## Image Processing and Computer Vision - Assignment Module \\#1\n","\n","\n","Contacts:\n","\n","- Prof. Giuseppe Lisanti -> giuseppe.lisanti@unibo.it\n","- Prof. Samuele Salti -> samuele.salti@unibo.it\n","- Alex Costanzino -> alex.costanzino@unibo.it\n","- Francesco Ballerini -> francesco.ballerini4@unibo.it\n","\n","\n","Computer vision-based object detection techniques can be applied in super market settings to build a system that can identify products on store shelves.\n","An example of how this system could be used would be to assist visually impaired customers or automate common store management tasks like detecting low-stock or misplaced products, given an image of a shelf in a store."],"metadata":{"id":"MNBgGYg_lpVN"}},{"cell_type":"markdown","source":["## Task\n","Develop a computer vision system that, given a reference image for each product, is able to identify such product from one picture of a store shelf.\n","\n","<figure>\n","<a href=\"https://imgbb.com/\">\n","  <center>\n","  <img src=\"https://i.ibb.co/TwkMWnH/Screenshot-2024-04-04-at-14-54-51.png\" alt=\"Screenshot-2024-04-04-at-14-54-51\" border=\"0\" width=\"300\" />\n","</a>\n","</figure>\n","\n","For each type of product displayed in the\n","shelf the system should report:\n","1. Number of instances;\n","1. Dimension of each instance (width and height in pixel of the bounding box that enclose them);\n","1. Position in the image reference system of each instance (center of the bounding box that enclose them).\n","\n","#### Example of expected output\n","```\n","Product 0 - 2 instance found:\n","  Instance 1 {position: (256, 328), width: 57px, height: 80px}\n","  Instance 2 {position: (311, 328), width: 57px, height: 80px}\n","Product 1 â€“ 1 instance found:\n",".\n",".\n",".\n","```\n","\n","### Track A - Single Instance Detection\n","Develop an object detection system to identify single instance of products given one reference image for each item and a scene image.\n","\n","The system should be able to correctly identify all the product in the shelves\n","image.\n","\n","### Track B - Multiple Instances Detection\n","In addition to what achieved at step A, the system should also be able to detect multiple instances of the same product."],"metadata":{"id":"DW42NlZsyTv0"}},{"cell_type":"markdown","source":["## Data\n","Two folders of images are provided:\n","* **Models**: contains one reference image for each product that the system should be able to identify.\n","* **Scenes**: contains different shelve pictures to test the developed algorithm in different scenarios. The images contained in this folder are corrupted by noise.\n","\n","#### Track A - Single Instance Detection\n","* **Models**: {ref1.png to ref14.png}.\n","* **Scenes**: {scene1.png to scene5.png}.\n","\n","#### Track B - Multiple Instances Detection\n","* **Models**: {ref15.png to ref27.png}.\n","* **Scenes**: {scene6.png to scene12.png}."],"metadata":{"id":"9fIbZJKq16ba"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp -r /content/drive/MyDrive/AssignmentsIPCV/dataset.zip ./\n","!unzip dataset.zip"],"metadata":{"id":"NjP3GCdujYlw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713346983910,"user_tz":-120,"elapsed":6059,"user":{"displayName":"Alessio Pittiglio","userId":"05557700667555665334"}},"outputId":"f30e1c5b-eb87-4ab3-b88b-c4bae5c34dce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Archive:  dataset.zip\n","   creating: dataset/\n","  inflating: __MACOSX/._dataset      \n","   creating: dataset/scenes/\n","  inflating: __MACOSX/dataset/._scenes  \n","  inflating: dataset/.DS_Store       \n","  inflating: __MACOSX/dataset/._.DS_Store  \n","   creating: dataset/models/\n","  inflating: __MACOSX/dataset/._models  \n","  inflating: dataset/scenes/scene12.png  \n","  inflating: __MACOSX/dataset/scenes/._scene12.png  \n","  inflating: dataset/scenes/scene10.png  \n","  inflating: __MACOSX/dataset/scenes/._scene10.png  \n","  inflating: dataset/scenes/scene11.png  \n","  inflating: __MACOSX/dataset/scenes/._scene11.png  \n","  inflating: dataset/scenes/scene5.png  \n","  inflating: __MACOSX/dataset/scenes/._scene5.png  \n","  inflating: dataset/scenes/scene4.png  \n","  inflating: __MACOSX/dataset/scenes/._scene4.png  \n","  inflating: dataset/scenes/scene6.png  \n","  inflating: __MACOSX/dataset/scenes/._scene6.png  \n","  inflating: dataset/scenes/scene7.png  \n","  inflating: __MACOSX/dataset/scenes/._scene7.png  \n","  inflating: dataset/scenes/scene3.png  \n","  inflating: __MACOSX/dataset/scenes/._scene3.png  \n","  inflating: dataset/scenes/scene2.png  \n","  inflating: __MACOSX/dataset/scenes/._scene2.png  \n","  inflating: dataset/scenes/scene1.png  \n","  inflating: __MACOSX/dataset/scenes/._scene1.png  \n","  inflating: dataset/scenes/scene9.png  \n","  inflating: __MACOSX/dataset/scenes/._scene9.png  \n","  inflating: dataset/scenes/scene8.png  \n","  inflating: __MACOSX/dataset/scenes/._scene8.png  \n","  inflating: dataset/models/ref8.png  \n","  inflating: __MACOSX/dataset/models/._ref8.png  \n","  inflating: dataset/models/ref9.png  \n","  inflating: __MACOSX/dataset/models/._ref9.png  \n","  inflating: dataset/models/ref12.png  \n","  inflating: __MACOSX/dataset/models/._ref12.png  \n","  inflating: dataset/models/ref13.png  \n","  inflating: __MACOSX/dataset/models/._ref13.png  \n","  inflating: dataset/models/ref11.png  \n","  inflating: __MACOSX/dataset/models/._ref11.png  \n","  inflating: dataset/models/ref10.png  \n","  inflating: __MACOSX/dataset/models/._ref10.png  \n","  inflating: dataset/models/ref14.png  \n","  inflating: __MACOSX/dataset/models/._ref14.png  \n","  inflating: dataset/models/ref15.png  \n","  inflating: __MACOSX/dataset/models/._ref15.png  \n","  inflating: dataset/models/ref17.png  \n","  inflating: __MACOSX/dataset/models/._ref17.png  \n","  inflating: dataset/models/ref16.png  \n","  inflating: __MACOSX/dataset/models/._ref16.png  \n","  inflating: dataset/models/ref27.png  \n","  inflating: __MACOSX/dataset/models/._ref27.png  \n","  inflating: dataset/models/ref26.png  \n","  inflating: __MACOSX/dataset/models/._ref26.png  \n","  inflating: dataset/models/ref18.png  \n","  inflating: __MACOSX/dataset/models/._ref18.png  \n","  inflating: dataset/models/ref24.png  \n","  inflating: __MACOSX/dataset/models/._ref24.png  \n","  inflating: dataset/models/ref25.png  \n","  inflating: __MACOSX/dataset/models/._ref25.png  \n","  inflating: dataset/models/ref19.png  \n","  inflating: __MACOSX/dataset/models/._ref19.png  \n","  inflating: dataset/models/ref21.png  \n","  inflating: __MACOSX/dataset/models/._ref21.png  \n","  inflating: dataset/models/ref20.png  \n","  inflating: __MACOSX/dataset/models/._ref20.png  \n","  inflating: dataset/models/ref22.png  \n","  inflating: __MACOSX/dataset/models/._ref22.png  \n","  inflating: dataset/models/ref23.png  \n","  inflating: __MACOSX/dataset/models/._ref23.png  \n","  inflating: dataset/models/ref7.png  \n","  inflating: __MACOSX/dataset/models/._ref7.png  \n","  inflating: dataset/models/ref6.png  \n","  inflating: __MACOSX/dataset/models/._ref6.png  \n","  inflating: dataset/models/ref4.png  \n","  inflating: __MACOSX/dataset/models/._ref4.png  \n","  inflating: dataset/models/ref5.png  \n","  inflating: __MACOSX/dataset/models/._ref5.png  \n","  inflating: dataset/models/ref1.png  \n","  inflating: __MACOSX/dataset/models/._ref1.png  \n","  inflating: dataset/models/ref2.png  \n","  inflating: __MACOSX/dataset/models/._ref2.png  \n","  inflating: dataset/models/ref3.png  \n","  inflating: __MACOSX/dataset/models/._ref3.png  \n"]}]},{"cell_type":"markdown","source":["## Evaluation criteria\n","1. **Procedural correctness**. There are several ways to solve the assignment. Design your own sound approach and justify every decision you make;\n","\n","2. **Clarity and conciseness**. Present your work in a readable way: format your code and comment every important step;\n","\n","3. **Correctness of results**. Try to solve as many instances as possible. You should be able to solve all the instances of the assignment, however, a thoroughly justified and sound procedure with a lower number of solved instances will be valued **more** than a poorly designed approach."],"metadata":{"id":"5KRBeGbKsEDe"}},{"cell_type":"code","source":["print(\"ciao\")"],"metadata":{"id":"YyGIT96JsnTP","executionInfo":{"status":"ok","timestamp":1714223758455,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alessio Arcara","userId":"18146927102459314818"}},"outputId":"217c0f6b-b9ec-44d1-c96d-b11c6d61d531","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ciao\n"]}]}]}