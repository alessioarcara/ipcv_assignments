{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNBgGYg_lpVN"
   },
   "source": [
    "# Assignment Module 2: Product Classification\n",
    "\n",
    "The goal of this assignment is to implement a neural network that classifies smartphone pictures of products found in grocery stores. The assignment will be divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVTQUJ4uYH1w"
   },
   "source": [
    "## Preliminaries: the dataset\n",
    "\n",
    "The dataset you will be using contains natural images of products taken with a smartphone camera in different grocery stores:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Granny-Smith.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Pink-Lady.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Lemon.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Banana.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Vine-Tomato.jpg\" width=\"150\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Yellow-Onion.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Green-Bell-Pepper.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Arla-Standard-Milk.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Oatly-Natural-Oatghurt.jpg\" width=\"150\">\n",
    "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Alpro-Fresh-Soy-Milk.jpg\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "The products belong to the following 43 classes:\n",
    "```\n",
    "0.  Apple\n",
    "1.  Avocado\n",
    "2.  Banana\n",
    "3.  Kiwi\n",
    "4.  Lemon\n",
    "5.  Lime\n",
    "6.  Mango\n",
    "7.  Melon\n",
    "8.  Nectarine\n",
    "9.  Orange\n",
    "10. Papaya\n",
    "11. Passion-Fruit\n",
    "12. Peach\n",
    "13. Pear\n",
    "14. Pineapple\n",
    "15. Plum\n",
    "16. Pomegranate\n",
    "17. Red-Grapefruit\n",
    "18. Satsumas\n",
    "19. Juice\n",
    "20. Milk\n",
    "21. Oatghurt\n",
    "22. Oat-Milk\n",
    "23. Sour-Cream\n",
    "24. Sour-Milk\n",
    "25. Soyghurt\n",
    "26. Soy-Milk\n",
    "27. Yoghurt\n",
    "28. Asparagus\n",
    "29. Aubergine\n",
    "30. Cabbage\n",
    "31. Carrots\n",
    "32. Cucumber\n",
    "33. Garlic\n",
    "34. Ginger\n",
    "35. Leek\n",
    "36. Mushroom\n",
    "37. Onion\n",
    "38. Pepper\n",
    "39. Potato\n",
    "40. Red-Beet\n",
    "41. Tomato\n",
    "42. Zucchini\n",
    "```\n",
    "\n",
    "The dataset is split into training (`train`), validation (`val`), and test (`test`) set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pdrmJRnJPd8"
   },
   "source": [
    "The following code cells download the dataset and define a `torch.utils.data.Dataset` class to access it. This `Dataset` class will be the starting point of your assignment: use it in your own code and build everything else around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "POMX_3x-_bZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'GroceryStoreDataset' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/marcusklasson/GroceryStoreDataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "hiF8xGEYlsu8"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "jROSO2qVDxdD"
   },
   "outputs": [],
   "source": [
    "class GroceryStoreDataset(Dataset):\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
    "        self.split = split\n",
    "        self.paths, self.labels = self.read_file()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img = Image.open(self.root / self.paths[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
    "        paths = []\n",
    "        labels = []\n",
    "\n",
    "        with open(self.root / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                # path, fine-grained class, coarse-grained class\n",
    "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
    "                paths.append(path), labels.append(int(label))\n",
    "\n",
    "        return paths, labels\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBch3dpwNSsW"
   },
   "source": [
    "## Part 1: design your own network\n",
    "\n",
    "Your goal is to implement a convolutional neural network for image classification and train it on `GroceryStoreDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split of **around 60%**. You are free to achieve that however you want, except for a few rules you must follow:\n",
    "\n",
    "- You **cannot** simply instantiate an off-the-self PyTorch network. Instead, you must construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you **cannot** use e.g. `torchvision.models.alexnet`.\n",
    "\n",
    "- Justify every *design choice* you make. Design choices include network architecture, training hyperparameters, and, possibly, dataset preprocessing steps. You can either (i) start from the simplest convolutional network you can think of and add complexity one step at a time, while showing how each step gets you closer to the target ~60%, or (ii) start from a model that is already able to achieve the desired accuracy and show how, by removing some of its components, its performance drops (i.e. an *ablation study*). You can *show* your results/improvements however you want: training plots, console-printed values or tables, or whatever else your heart desires: the clearer, the better.\n",
    "\n",
    "Don't be too concerned with your network performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded **more** points than a poorly experimentally validated model with higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from functools import partial\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import io\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: runs/*\n"
     ]
    }
   ],
   "source": [
    "!rm -r runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 20,\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"ls\": 0.01,\n",
    "    \"weight_decay\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.RandomResizedCrop(size=(384, 384), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "transform_no_augmentation = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "train_dataset = GroceryStoreDataset(\"train\", transform=transform)\n",
    "val_dataset = GroceryStoreDataset(\"val\", transform=transform_no_augmentation)\n",
    "test_dataset = GroceryStoreDataset(\"test\", transform=transform_no_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_class_distribution(dataset, title=\"Class Distribution\"):\n",
    "    class_count = {}\n",
    "    for _, label in dataset:\n",
    "        class_count[label] = class_count.get(label, 0) + 1\n",
    "    \n",
    "    labels = list(class_count.keys())\n",
    "    counts = list(class_count.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, counts)\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_dataset, title=\"Training Dataset Class Distribution\")\n",
    "plot_class_distribution(test_dataset, title=\"Validation Dataset Class Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{torch.Size([3, 348, 348]),\n",
       " torch.Size([3, 348, 464]),\n",
       " torch.Size([3, 464, 348])}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(img.shape for img, _ in test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int,\n",
    "        use_bn: bool = True,\n",
    "        act: nn.Module = nn.ReLU(inplace=True),\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_features,\n",
    "            out_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.norm = nn.BatchNorm2d(out_features) if use_bn else nn.Identity()\n",
    "        self.act = act if act is not None else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "Conv1X1BnRelu = partial(ConvBnRelu, kernel_size=1)\n",
    "Conv3X3BnRelu = partial(ConvBnRelu, kernel_size=3)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features, \n",
    "        out_features,\n",
    "        stride = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        reduced_features = out_features // 4\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            Conv1X1BnRelu(in_features, reduced_features),\n",
    "            Conv3X3BnRelu(reduced_features, reduced_features, stride=stride),\n",
    "            Conv1X1BnRelu(reduced_features, out_features, act=None)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.skip = nn.Identity()\n",
    "        if stride != 1 or in_features != out_features:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_features, out_features, 1, stride),\n",
    "                nn.BatchNorm2d(out_features)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = self.block(x) + identity\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Conv2d(1024, 43, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = self.make_layer(64, 128, 1, num_blocks[0])\n",
    "        self.layer2 = self.make_layer(128, 256, 2, num_blocks[1])\n",
    "        self.layer3 = self.make_layer(256, 512, 2, num_blocks[2])\n",
    "        self.layer4 = self.make_layer(512, 1024, 2, num_blocks[3])\n",
    "        self.classifier = nn.Conv2d(1024, num_classes, kernel_size=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def make_layer(self, in_features, out_features, stride, num_blocks):\n",
    "        layers = []\n",
    "        layers.append(ResBlock(in_features, out_features, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResBlock(out_features, out_features))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # out = self.classifier(out)  # Shape: [batch_size, num_classes, h, w]\n",
    "        # out = F.adaptive_avg_pool2d(out, (1, 1))  # Shape: [batch_size, num_classes, 1, 1]\n",
    "        # out = out.view(out.size(0), -1)  # Flatten to [batch_size, num_classes]\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = ResNet([2, 2, 2, 2], num_classes=train_dataset.get_num_classes())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  num_classes = len(class_names)\n",
    "  fig, ax = plt.subplots(figsize=(max(8, num_classes * 0.7), max(6, num_classes * 0.7)))\n",
    "  im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  ax.set_title(\"Confusion matrix\", fontsize=20)\n",
    "  tick_marks = np.arange(num_classes)\n",
    "  ax.set_xticks(tick_marks)\n",
    "  ax.set_yticks(tick_marks)\n",
    "  plt.xticks(fontsize=18, rotation=90)\n",
    "  plt.yticks(fontsize=18)\n",
    "\n",
    "\n",
    "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "  cm_normalized = np.nan_to_num(cm_normalized)\n",
    "  \n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in np.ndindex(cm.shape):\n",
    "      ax.text(j, i, f\"{cm[i, j]}\\n({cm_normalized[i, j]:.2f})\",\n",
    "              horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\",\n",
    "              fontsize=max(6, 10 - 0.3 * num_classes),  # Adjust font size based on number of classes\n",
    "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  ax.set_ylabel('True label')\n",
    "  ax.set_xlabel('Predicted label')\n",
    "\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')\n",
    "  plt.close(fig)\n",
    "  buf.seek(0)\n",
    "\n",
    "  image = Image.open(buf)\n",
    "  return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, model, train_loader, val_loader, loss_fn, optimizer, class_names=None):\n",
    "    writer = SummaryWriter(log_dir=config.get('tensorboard_log_dir', './logs'))\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with tqdm.tqdm(train_loader, total=len(train_loader)) as pbar:\n",
    "            for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, pred = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += pred.eq(labels).sum().item()\n",
    "\n",
    "                train_loss = running_loss / (batch_idx + 1)\n",
    "                train_acc = correct / total\n",
    "\n",
    "                global_step = epoch * len(train_loader) + batch_idx\n",
    "                writer.add_scalar('Loss/Train_Step', loss.item(), global_step)\n",
    "                writer.add_scalar('Accuracy/Train_Step', pred.eq(labels).sum().item() / labels.size(0), global_step)\n",
    "    \n",
    "                pbar.set_postfix({\n",
    "                        'Epoch': f\"{epoch+1}/{config['num_epochs']}\",\n",
    "                        'train_loss': f\"{train_loss:.4f}\",\n",
    "                        'train_acc': f\"{train_acc:.4f}\"\n",
    "                })\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            \n",
    "            val_loss, val_acc, all_preds, all_labels = eval_model(model, val_loader, loss_fn)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{config['num_epochs']}], \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            writer.add_scalar('Loss/Train_Epoch', train_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/Train_Epoch', train_acc, epoch)\n",
    "            writer.add_scalar('Loss/Validation_Epoch', val_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/Validation_Epoch', val_acc, epoch)\n",
    "\n",
    "            if class_names is not None:\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                img = plot_confusion_matrix(cm, class_names)\n",
    "                transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "                img_tensor = transform(img)\n",
    "                writer.add_image('Confusion Matrix', img_tensor, epoch, dataformats='CHW')\n",
    "\n",
    "            # if val_acc > best_val_acc:\n",
    "            #     best_val_acc = val_acc\n",
    "            #     epochs_no_improve = 0\n",
    "            #     torch.save(model.state_dict(), f'../models/best_model.pch')\n",
    "            #     print(\"Model saved!\")\n",
    "            # else:\n",
    "            #     epochs_no_improve += 1\n",
    "\n",
    "            # if epochs_no_improve >= config['patience']:\n",
    "            #     print(\"Early stopping!\")\n",
    "            #     break\n",
    "            \n",
    "    writer.close()\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "            \n",
    "def eval_model(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, pred = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_acc = correct / total \n",
    "\n",
    "    return val_loss, val_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(label_smoothing=config[\"ls\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:44<00:00,  1.88it/s, Epoch=1/20, train_loss=1.9212, train_acc=0.4348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 1.9212, Train Acc: 0.4348, Val Loss: 3.5058, Val Acc: 0.3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.83it/s, Epoch=2/20, train_loss=1.6474, train_acc=0.4890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Train Loss: 1.6474, Train Acc: 0.4890, Val Loss: 2.4861, Val Acc: 0.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:46<00:00,  1.77it/s, Epoch=3/20, train_loss=1.5647, train_acc=0.5261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Train Loss: 1.5647, Train Acc: 0.5261, Val Loss: 2.4223, Val Acc: 0.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.82it/s, Epoch=4/20, train_loss=1.5023, train_acc=0.5458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Train Loss: 1.5023, Train Acc: 0.5458, Val Loss: 1.7433, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.83it/s, Epoch=5/20, train_loss=1.3713, train_acc=0.5708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Train Loss: 1.3713, Train Acc: 0.5708, Val Loss: 2.1554, Val Acc: 0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:46<00:00,  1.77it/s, Epoch=6/20, train_loss=1.2568, train_acc=0.6345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Train Loss: 1.2568, Train Acc: 0.6345, Val Loss: 2.7757, Val Acc: 0.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:47<00:00,  1.76it/s, Epoch=7/20, train_loss=1.2813, train_acc=0.6277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Train Loss: 1.2813, Train Acc: 0.6277, Val Loss: 2.5503, Val Acc: 0.3716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:47<00:00,  1.76it/s, Epoch=8/20, train_loss=1.2181, train_acc=0.6413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Train Loss: 1.2181, Train Acc: 0.6413, Val Loss: 2.7446, Val Acc: 0.3953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:46<00:00,  1.78it/s, Epoch=9/20, train_loss=1.1348, train_acc=0.6640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Train Loss: 1.1348, Train Acc: 0.6640, Val Loss: 2.0469, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:48<00:00,  1.71it/s, Epoch=10/20, train_loss=1.0637, train_acc=0.6955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Train Loss: 1.0637, Train Acc: 0.6955, Val Loss: 2.4945, Val Acc: 0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.82it/s, Epoch=11/20, train_loss=1.0408, train_acc=0.6951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Train Loss: 1.0408, Train Acc: 0.6951, Val Loss: 2.6993, Val Acc: 0.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:51<00:00,  1.62it/s, Epoch=12/20, train_loss=0.9937, train_acc=0.7170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Train Loss: 0.9937, Train Acc: 0.7170, Val Loss: 1.8688, Val Acc: 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.81it/s, Epoch=13/20, train_loss=0.9276, train_acc=0.7409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Train Loss: 0.9276, Train Acc: 0.7409, Val Loss: 1.9704, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:53<00:00,  1.56it/s, Epoch=14/20, train_loss=0.8862, train_acc=0.7383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Train Loss: 0.8862, Train Acc: 0.7383, Val Loss: 1.9741, Val Acc: 0.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:45<00:00,  1.82it/s, Epoch=15/20, train_loss=0.8993, train_acc=0.7462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Train Loss: 0.8993, Train Acc: 0.7462, Val Loss: 2.0086, Val Acc: 0.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [00:46<00:00,  1.78it/s, Epoch=16/20, train_loss=0.8554, train_acc=0.7625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Train Loss: 0.8554, Train Acc: 0.7625, Val Loss: 2.3116, Val Acc: 0.4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [12:46<00:00,  9.23s/it, Epoch=17/20, train_loss=0.8202, train_acc=0.7773]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Train Loss: 0.8202, Train Acc: 0.7773, Val Loss: 1.6174, Val Acc: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [22:39<00:00, 16.37s/it, Epoch=18/20, train_loss=0.7952, train_acc=0.7886]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Train Loss: 0.7952, Train Acc: 0.7886, Val Loss: 1.9546, Val Acc: 0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [06:47<00:00,  4.91s/it, Epoch=19/20, train_loss=0.7849, train_acc=0.7795]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Train Loss: 0.7849, Train Acc: 0.7795, Val Loss: 1.9154, Val Acc: 0.4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "100%|██████████| 83/83 [05:54<00:00,  4.28s/it, Epoch=20/20, train_loss=0.7624, train_acc=0.7939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Train Loss: 0.7624, Train Acc: 0.7939, Val Loss: 3.1423, Val Acc: 0.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_47159/18754019.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.921210501567427,\n",
       "  1.6473949429500534,\n",
       "  1.5647044598338116,\n",
       "  1.5022728773484748,\n",
       "  1.3712722242596638,\n",
       "  1.2567624155297337,\n",
       "  1.2812651848218528,\n",
       "  1.2181303982275078,\n",
       "  1.134814179805388,\n",
       "  1.0636605268501373,\n",
       "  1.040808411247759,\n",
       "  0.9937186672026852,\n",
       "  0.9275650741106056,\n",
       "  0.8862173729632274,\n",
       "  0.8993457038718534,\n",
       "  0.855432270521141,\n",
       "  0.8202451833759445,\n",
       "  0.7951832359813782,\n",
       "  0.7849447727203369,\n",
       "  0.7623959273458963],\n",
       " [0.4348484848484849,\n",
       "  0.4890151515151515,\n",
       "  0.5261363636363636,\n",
       "  0.5458333333333333,\n",
       "  0.5708333333333333,\n",
       "  0.634469696969697,\n",
       "  0.6276515151515152,\n",
       "  0.6412878787878787,\n",
       "  0.6640151515151516,\n",
       "  0.6954545454545454,\n",
       "  0.6950757575757576,\n",
       "  0.7170454545454545,\n",
       "  0.740909090909091,\n",
       "  0.7382575757575758,\n",
       "  0.7462121212121212,\n",
       "  0.7625,\n",
       "  0.7772727272727272,\n",
       "  0.7886363636363637,\n",
       "  0.7795454545454545,\n",
       "  0.793939393939394],\n",
       " [3.5058236718177795,\n",
       "  2.486116874217987,\n",
       "  2.4222503185272215,\n",
       "  1.743341612815857,\n",
       "  2.155417823791504,\n",
       "  2.775711438059807,\n",
       "  2.5503286719322205,\n",
       "  2.7446311712265015,\n",
       "  2.0469240665435793,\n",
       "  2.494527888298035,\n",
       "  2.699289321899414,\n",
       "  1.8687639951705932,\n",
       "  1.9703734397888184,\n",
       "  1.9741498231887817,\n",
       "  2.00856574177742,\n",
       "  2.3115540385246276,\n",
       "  1.6174069404602052,\n",
       "  1.9545796930789947,\n",
       "  1.915377926826477,\n",
       "  3.1422977685928344],\n",
       " [0.32432432432432434,\n",
       "  0.32094594594594594,\n",
       "  0.3310810810810811,\n",
       "  0.48986486486486486,\n",
       "  0.36824324324324326,\n",
       "  0.3918918918918919,\n",
       "  0.3716216216216216,\n",
       "  0.3952702702702703,\n",
       "  0.48986486486486486,\n",
       "  0.38513513513513514,\n",
       "  0.4189189189189189,\n",
       "  0.47635135135135137,\n",
       "  0.48986486486486486,\n",
       "  0.5033783783783784,\n",
       "  0.4864864864864865,\n",
       "  0.42905405405405406,\n",
       "  0.5641891891891891,\n",
       "  0.4966216216216216,\n",
       "  0.4594594594594595,\n",
       "  0.38175675675675674])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(config, model, train_loader, val_loader, loss, optimizer, range(0, train_dataset.get_num_classes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkWEqSPoUIL3"
   },
   "source": [
    "## Part 2: fine-tune an existing network\n",
    "\n",
    "Your goal is to fine-tune a pretrained **ResNet-18** model on `GroceryStoreDataset`. Use the implementation provided by PyTorch, do not implement it yourselves! (i.e. exactly what you **could not** do in the first part of the assignment). Specifically, you must use the PyTorch ResNet-18 model pretrained on ImageNet-1K (V1). Divide your fine-tuning into two parts:\n",
    "\n",
    "1. First, fine-tune the Resnet-18 with the same training hyperparameters you used for your best model in the first part of the assignment.\n",
    "1. Then, tweak the training hyperparameters in order to increase the accuracy on the validation split of `GroceryStoreDataset`. Justify your choices by analyzing the training plots and/or citing sources that guided you in your decisions (papers, blog posts, YouTube videos, or whatever else you find enlightening). You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split **between 80 and 90%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
